# Model Task Extension Template
# Use this template for extensions that use an LLM to process inputs

name: my_model_extension
version: 1.0.0
description: Extension that uses an LLM model to process inputs

inputs:
  type: object
  properties:
    text:
      type: string
      description: Input text to process
  required:
    - text

outputs:
  type: object
  properties:
    result:
      type: string
      description: Processed result from the model
    confidence:
      type: number
      minimum: 0
      maximum: 1
      description: Confidence score (optional)
  required:
    - result

task:
  type: model

# Model configuration
model:
  provider: ollama  # Change to your LLM provider (ollama, lm_studio, etc.)
  model_name: llama3.2  # Change to your available model
  temperature: 0.7
  max_tokens: 1000

# Prompt template (use {{inputs.field_name}} to reference inputs)
prompt: |
  You are a helpful assistant. Process the following text:
  
  {{inputs.text}}
  
  Provide a clear and concise response.

# Guardrails
guardrails:
  - type: no_network_access
    enabled: true
  - type: no_filesystem_access
    enabled: true
  - type: max_output_length
    value: 5000

# Observability (logging and metrics)
observability:
  logging:
    enabled: true
    level: info
  metrics:
    enabled: true
    track_latency: true
